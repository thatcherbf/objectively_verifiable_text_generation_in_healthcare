{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pfY-hRaihWS"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzM4C14HZR2A"
      },
      "source": [
        "## Drive integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQbI8kGho3Ej"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mme0ACl1ZViJ"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlJAWqhFWok1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dno0YgNQZXnv"
      },
      "source": [
        "## Free GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHx8GpcbZXVN"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "def free_gpu_memory():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qthv0WUnKtEr"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWBuBRcuurk_"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDkZNO2DunNV"
      },
      "source": [
        "# Classifier Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TWKtEdHurk_"
      },
      "outputs": [],
      "source": [
        "q1 = pd.read_csv('/content/drive/MyDrive/data/csv/queries.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bgttq1BurlA"
      },
      "outputs": [],
      "source": [
        "q1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIzumX_BWOOg"
      },
      "outputs": [],
      "source": [
        "label_mapping = {'quantitative analysis': 0, 'general information': 1, 'miscellaneous':2}\n",
        "q1['label'] = q1['label'].map(label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwHv1km6urlA"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained BioBERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "model = BertForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=3)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1h1RVfClkla"
      },
      "outputs": [],
      "source": [
        "encoded_batch = tokenizer(\n",
        "    list(q1['text']),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=256,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VWX6EmRLL-C"
      },
      "outputs": [],
      "source": [
        "input_ids = encoded_batch['input_ids']\n",
        "attention_masks = encoded_batch['attention_mask']\n",
        "labels = torch.tensor(q1['label'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpOxHyRNiHzm"
      },
      "outputs": [],
      "source": [
        "# Data split\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    input_ids, labels,\n",
        "    test_size = 0.1, stratify = labels\n",
        ")\n",
        "\n",
        "train_masks, val_masks, _, _ = train_test_split(\n",
        "    attention_masks, labels,\n",
        "    test_size = 0.1, stratify = labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SICKBr_1LQPn"
      },
      "outputs": [],
      "source": [
        "# Create TensorDatasets\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "\n",
        "# Define Samplers & Loaders\n",
        "train_dataloader = DataLoader(train_data, sampler = RandomSampler(train_data), batch_size = 32)\n",
        "val_dataloader = DataLoader(val_data, sampler = SequentialSampler(val_data), batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VVTxqx1urlB"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./results\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    per_device_train_batch_size = 32,\n",
        "    per_device_eval_batch_size = 32,\n",
        "    num_train_epochs = 10,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieQYOfwogtZY"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_data,\n",
        "    eval_dataset = val_data,\n",
        "    tokenizer = tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gO1ctwhNyaq"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffz3OpL7L5ar"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHYygWBgurlC"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcSHIJsbMXyi"
      },
      "outputs": [],
      "source": [
        "# Define batch classification function\n",
        "def classify_batch(model, tokenizer, texts, label_dict):\n",
        "    input_ids, attention_masks = encode_data(tokenizer, texts)\n",
        "    input_ids, attention_masks = input_ids.to(device), attention_masks.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_masks)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "    return [label_dict[p] for p in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "540mqgV3NUgB"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "label_dict = {0: 'quantitative analysis', 1: 'general information', 2: 'miscellaneous'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7kSB9DAurlC"
      },
      "outputs": [],
      "source": [
        "new_texts = [\n",
        "    \"How much is 5 multiplied by 10?\",\n",
        "    \"What is the capital of France?\",\n",
        "    \"What is the square root of 16?\",\n",
        "    \"How many planets are there in the solar system?\",\n",
        "    \"What is my risk for cardiovascular disease if my blood pressure goes up to 180?\",\n",
        "    \"What causes the buildup of plaque in the arteries?\",\n",
        "    \"What are the main causes of atherosclerosis?\",\n",
        "    \"Is there a correlation between developing diabetes and the risk of cardiovascular disease?\",\n",
        "    \"Will developing diabetes affect my risk of developing cardiovascular disease?\",\n",
        "    \"Can I get tickets to the 9:00 showing of Cats?\",\n",
        "    \"What will happen to my risk of cardiovascular disease if my blood pressure increases by 50%?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yRVxHMHurlD"
      },
      "outputs": [],
      "source": [
        "predictions = classify_batch(model, tokenizer, new_texts, label_dict)\n",
        "for text, label in zip(new_texts, predictions):\n",
        "    print(text, \"->\", label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpOCjiLvnwjh"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5toHUeWurlE"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/classifiers/v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oovwZt5urlE"
      },
      "outputs": [],
      "source": [
        "classifier_v1 = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/classifiers/v1')\n",
        "classifier_v1.to(device)\n",
        "classifier_v1.eval()\n",
        "print(\"Classifier loaded successfully.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
