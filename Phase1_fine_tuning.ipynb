{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "d-OQngtx4CQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --quiet"
      ],
      "metadata": {
        "id": "IMXK2n0r8vsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers --quiet"
      ],
      "metadata": {
        "id": "ccA8yGo682Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUzELRkZIKUL"
      },
      "outputs": [],
      "source": [
        "!pip install -i https://pypi.org/simple/ bitsandbytes --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate --upgrade --quiet"
      ],
      "metadata": {
        "id": "9U5iFt9BIQ9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet"
      ],
      "metadata": {
        "id": "VElB7oFJJ_zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF pdfminer.six --quiet"
      ],
      "metadata": {
        "id": "kWwDVYhLIYli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft --quiet"
      ],
      "metadata": {
        "id": "1Y-Iyo0DIbn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl --quiet"
      ],
      "metadata": {
        "id": "_2ZE8eSxQdM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "5gedqt4l4FXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bitsandbytes\n",
        "import accelerate"
      ],
      "metadata": {
        "id": "FO9kSxMiI3Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "68idbHAQI66f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "ZFUVC0AY9d-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "5wrVWQAmVPCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "oUfcnU8kMcBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "7a1og9jipnNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace/Drive integration"
      ],
      "metadata": {
        "id": "fx9lfYVO4Nj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "Z3yVsnXRMeT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pPVZAlZaIoZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU"
      ],
      "metadata": {
        "id": "iRQJgOXN4QKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check device availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "TNLxUdu8Iky0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Free GPU memory"
      ],
      "metadata": {
        "id": "ks79UzLl4RqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def free_gpu_memory():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "2u9euLsD9gnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load LLM"
      ],
      "metadata": {
        "id": "vKIQN5WV4TVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "uncFKFZuJkHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "auth_token = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "oHACt7s6JvP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    token=auth_token,\n",
        "    cache_dir = '/content/drive/MyDrive/model',\n",
        ")"
      ],
      "metadata": {
        "id": "17Z0BFgRKRh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "XchDlSN8KSVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "dIrr8Iy7vMMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=auth_token,\n",
        "    cache_dir = '/content/drive/MyDrive/model',\n",
        "    torch_dtype=torch.float16,\n",
        "    rope_scaling={\"type\": \"dynamic\", \"factor\": 2},\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map = \"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")"
      ],
      "metadata": {
        "id": "Of_DN4PVLIo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing"
      ],
      "metadata": {
        "id": "bJiGRfvZR1Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "_l-S0pJmKt6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Can you briefly explain the concept of atherosclerosis in the context of LDL cholesterol and cardiovascular health?\"\n",
        "\n",
        "prompt_with_system_prompt = f\"User: {prompt} Assistant: \"\n",
        "\n",
        "inputs = tokenizer(prompt_with_system_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    #max_length=150,\n",
        "    temperature=0.5,\n",
        "    top_p=0.75\n",
        ")\n",
        "\n",
        "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "display(Markdown(f\"\\n'''\\n{response_text.split('Assistant: ')[-1].strip()}\\n'''\\n\"))"
      ],
      "metadata": {
        "id": "ZFx43fQ8uoG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1"
      ],
      "metadata": {
        "id": "8sOvT0Jo4XRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text"
      ],
      "metadata": {
        "id": "U_4EqQVlvPZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdfs(pdf_paths):\n",
        "    texts = []\n",
        "    for path in pdf_paths:\n",
        "        text = extract_text(path)\n",
        "        texts.append(text)\n",
        "    return texts"
      ],
      "metadata": {
        "id": "mAjPgvEEJv_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "pdf_path = \"/content/drive/MyDrive/data\""
      ],
      "metadata": {
        "id": "xm28OkPJJv_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_paths = glob.glob(pdf_path+\"/*.pdf\")"
      ],
      "metadata": {
        "id": "mQuq6l08Jv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = extract_text_from_pdfs(pdf_paths)"
      ],
      "metadata": {
        "id": "d6Pe3Vb6Jv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove header/footer artifacts\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple whitespaces with single space\n",
        "    text = re.sub(r'(\\n){2,}', '\\n', text)  # Replace multiple newlines with a single newline\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
        "\n",
        "    # Remove common but unnecessary items like references or excess newlines\n",
        "    text = text.replace('\\n', ' ')  # Replace new lines with space to maintain continuity\n",
        "    return text"
      ],
      "metadata": {
        "id": "F57GelOmJv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [clean_text(text) for text in texts]"
      ],
      "metadata": {
        "id": "afIzXLmeJv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size = 512, overlap = 50):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  chunks = []\n",
        "  for i in range(0, len(tokens), chunk_size - overlap):\n",
        "    chunk = tokens[i:i + chunk_size]\n",
        "    chunks.append(tokenizer.convert_tokens_to_string(chunk))\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "ho8tgoeSJv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenize function\n",
        "def tokenize_function(examples):\n",
        "  all_chunks = []\n",
        "  for example in examples['text']:\n",
        "    chunks = chunk_text(example)\n",
        "    for chunk in chunks:\n",
        "      tokenized_chunk = tokenizer(chunk, padding=\"max_length\", truncation=True, max_length=512)\n",
        "      all_chunks.append(tokenized_chunk)\n",
        "\n",
        "  # Transform list of tokenized chunks into a dictionary of lists\n",
        "  batch = {key: [] for key in all_chunks[0].keys()}\n",
        "  for chunk in all_chunks:\n",
        "    for key, value in chunk.items():\n",
        "      batch[key].append(value)\n",
        "  return batch"
      ],
      "metadata": {
        "id": "9gTd1SEWJv_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset from the extracted texts\n",
        "texts_dataset = Dataset.from_dict({\"text\": texts})\n",
        "tokenized_dataset = texts_dataset.map(tokenize_function, batched = True, remove_columns=[\"text\"])"
      ],
      "metadata": {
        "id": "UrD84o0CJv_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels (in causal language modeling, labels are the same as input_ids)\n",
        "def add_labels(example):\n",
        "    example['labels'] = example['input_ids'].copy()\n",
        "    return example\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.map(add_labels, batched=False)"
      ],
      "metadata": {
        "id": "hrBSJRjFjVHg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}