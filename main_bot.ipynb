{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial installs"
      ],
      "metadata": {
        "id": "KzlAGGJEe3li"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG3xcE3SMUO_"
      },
      "outputs": [],
      "source": [
        "!pip install -i https://pypi.org/simple/ bitsandbytes --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7l6Pm3yMVcN"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF --quiet"
      ],
      "metadata": {
        "id": "I-59y8xFohIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet"
      ],
      "metadata": {
        "id": "VXLYq2lcseA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Pmg3K6IjVyIw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X38U9DPYMa20"
      },
      "outputs": [],
      "source": [
        "import bitsandbytes\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IqjjIaVMcB0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, BertTokenizer, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVH9ojzyxc-U"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify, send_file\n",
        "from pyngrok import ngrok\n",
        "import requests\n",
        "import json\n",
        "import math\n",
        "import gc\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from google.colab import drive, userdata"
      ],
      "metadata": {
        "id": "YS0CjhnJqe-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import llama_index\n",
        "import llama_index.readers\n",
        "import llama_index.readers.file\n",
        "from llama_index.readers.file import PyMuPDFReader\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, download_loader\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "etyBhoLkq5ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace/Drive interfacing"
      ],
      "metadata": {
        "id": "8B5JK10te9j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "Xhpos-g_w5a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsIMFzk6MfAz"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU"
      ],
      "metadata": {
        "id": "ENlFRCB5fEEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksmNxIWBMeAs"
      },
      "outputs": [],
      "source": [
        "# Check device availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Free GPU Memory"
      ],
      "metadata": {
        "id": "4A38W04UTPKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def free_gpu_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "YQvGvA2ITO6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load in the model"
      ],
      "metadata": {
        "id": "XLqgTI98euvF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAubK-BuMgjd"
      },
      "outputs": [],
      "source": [
        "# Load tokenizer and final trained model\n",
        "model_directory = \"/content/drive/MyDrive/saved_models/LLama2-7B-chat-PT1-v2\"\n",
        "auth_token = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_directory,\n",
        "    local_files_only = True\n",
        ")"
      ],
      "metadata": {
        "id": "fsjYm73Wx5r3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJf7TT2EMiAr"
      },
      "outputs": [],
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_directory,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    rope_scaling={\"type\": \"dynamic\", \"factor\": 2},\n",
        "    local_files_only = True,\n",
        "    quantization_config=quantization_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "WK7i9RIjc70d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load initial classifier"
      ],
      "metadata": {
        "id": "TDn6pvgCeB5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "stage1_classifier = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/classifiers/v1')"
      ],
      "metadata": {
        "id": "NyY81_8IeIQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stage1_classifier.to(device)\n",
        "stage1_classifier.eval()\n",
        "print(\"Classifer loaded successfully.\")"
      ],
      "metadata": {
        "id": "iN1ESTjCeJrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data(tokenizer, texts, max_len=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "97qnmCQYe37X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(model, tokenizer, text, label_dict):\n",
        "    input_ids, attention_masks = encode_data(tokenizer, [text])\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_masks = attention_masks.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
        "\n",
        "    prediction_idx = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return label_dict[prediction_idx]"
      ],
      "metadata": {
        "id": "R3dFK5EQe6fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {0: 'quantitative analysis', 1: 'general information', 2: 'miscellaneous'}"
      ],
      "metadata": {
        "id": "AxOygYBZe-Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Webpage layout interface"
      ],
      "metadata": {
        "id": "SeLOAGlsew-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STATIC_DIR = os.path.abspath('/content/interface/static')"
      ],
      "metadata": {
        "id": "UCko-PoyV2wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Branches"
      ],
      "metadata": {
        "id": "Y-5AetXurLUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge branch"
      ],
      "metadata": {
        "id": "47Qtwm_urMdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_system_prompt = \"\"\"[INST] <<SYS>>\n",
        "You are an informative assistant called \"Assistant\". Your goal is to provide accurate and relevant information about Cardiovascular disease and adjacent topics in response to the user's queries.\n",
        "Please ensure that your responses are informative, helpful, direct, dispassionate, and factual. Respond in plain English, and aim for your response to be at least 3 sentences in length.\n",
        "If you're uncertain about a question, it's better to admit it rather than provide inaccurate information.\n",
        "<</SYS>>\n",
        "\"\"\"\n",
        "\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"{query_str}\\nAssistant: [/INST]\")"
      ],
      "metadata": {
        "id": "Ht-MqDF2rOAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a HF LLM using the llama index wrapper\n",
        "knowledge_llm = HuggingFaceLLM(\n",
        "    context_window = 4096,\n",
        "    max_new_tokens = 512,\n",
        "    generate_kwargs = {\"temperature\": 0.6},\n",
        "    system_prompt = knowledge_system_prompt,\n",
        "    query_wrapper_prompt = query_wrapper_prompt,\n",
        "    model = model,\n",
        "    tokenizer = tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "5BqphHTCsxkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and dl embeddings instance\n",
        "embeddings = LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
        ")"
      ],
      "metadata": {
        "id": "t0zIaHoqszLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and index multiple PDF documents\n",
        "def load_and_index_documents(directory_path):\n",
        "    loader = PyMuPDFReader()\n",
        "    all_documents = []\n",
        "    for pdf_file in Path(directory_path).rglob('*.pdf'):\n",
        "        documents = loader.load(file_path = pdf_file, metadata = True)\n",
        "        all_documents.extend(documents)\n",
        "\n",
        "    # Create an index with all documents\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        all_documents,\n",
        "        embed_model = embeddings\n",
        "    )\n",
        "    return index"
      ],
      "metadata": {
        "id": "tGOvPbAYs0Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and index documents from a specified directory\n",
        "directory_path = '/content/drive/MyDrive/data/'\n",
        "doc_index = load_and_index_documents(directory_path)\n",
        "\n",
        "def serve_knowledge(prompt):\n",
        "    # Setup index query engine using LLM\n",
        "    query_engine = doc_index.as_query_engine(llm = knowledge_llm)\n",
        "\n",
        "    response = query_engine.query(prompt)\n",
        "    return {\"answer\": response.response.strip()}"
      ],
      "metadata": {
        "id": "ULuHewJns1Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantitative branch"
      ],
      "metadata": {
        "id": "of-yr-bIrU1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate functions"
      ],
      "metadata": {
        "id": "Zqahz6h21SrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average LDL values for men and women from ages 30 to 80\n",
        "men_mean_LDL = [3.3174731188868307, 3.334143838077217, 3.350898329725846, 3.3677370147998453, 3.3846603163817544, 3.4016686596801553, 3.4187624720403567, 3.435942182955132, 3.45320822407551, 3.4705610292216185, 3.4880010343935868, 3.4955003878975948, 3.54100077579519, 3.555500387897595, 3.611998965606413, 3.655001292991983, 3.6629997414016033, 3.6299999999999994, 3.6829997414016034, 3.6814998707008013, 3.695500387897595, 3.68899922420481, 3.700499094905611, 3.724998707008017, 3.7459994828032066, 3.7070002585983968, 3.7089992242048098, 3.714000517196793, 3.721499870700802, 3.714000517196793, 3.718500129299198, 3.69899922420481, 3.6940005171967933, 3.6870002585983968, 3.6940005171967933, 3.6570002585983965, 3.6470002585983967, 3.6449987070080163, 3.631998965606413, 3.613838970778381, 3.595769775924489, 3.5777909270448665, 3.559901972409642, 3.542102462547594, 3.524391950234856, 3.506769990483682, 3.4892361405312635, 3.471789959828607, 3.454431010029464, 3.437158854979317, 3.41997306070442]\n",
        "women_mean_LDL = [2.861743860038676, 2.8833691285024443, 2.905157812093143, 2.9271111456857857, 2.949230373486938, 2.971516749105227, 2.9939715356223946, 3.016596005664881, 3.03939144147595, 3.062359134988363, 3.085500387897595, 3.0970002585983964, 3.12, 3.162999741401603, 3.1659994828032065, 3.2199999999999998, 3.2514998707008016, 3.3110007757951894, 3.351998965606413, 3.43, 3.497000258598397, 3.5314998707008014, 3.601998965606413, 3.654000517196793, 3.7199999999999998, 3.7695009050943886, 3.7919989656064126, 3.821998965606413, 3.8435014222911814, 3.83899922420481, 3.9010007757951897, 3.9270002585983965, 3.934998707008017, 3.9259994828032063, 3.9440005171967933, 3.9495009050943883, 3.9449987070080166, 3.9380010343935865, 3.9570002585983968, 3.9329997414016034, 3.9529997414016034, 3.9332347426945957, 3.9135685689811224, 3.8940007261362166, 3.8745307225055354, 3.8551580688930076, 3.8358822785485422, 3.8167028671558, 3.797619352820021, 3.7786312560559208, 3.759738099775641]\n",
        "\n",
        "# average SBP values for men and women from ages 30 to 80\n",
        "men_mean_SBP = [127.09770000000009, 127.64270000000009, 128.1877000000001, 128.73270000000008, 129.27770000000007, 129.82270000000005, 130.36770000000004, 130.91270000000003, 131.45770000000002, 132.0027, 132.5477, 132.5595, 133.0417, 133.9244, 133.8602, 134.1759, 134.8107, 135.0133, 136.0058, 136.2948, 136.8521, 137.2601, 137.7067, 138.7961, 139.1646, 139.5142, 140.0917, 140.7533, 141.3936, 142.006, 142.6065, 143.1211, 143.6272, 144.0828, 145.4364, 145.5392, 146.494, 146.6693, 146.9347, 147.3451, 147.8901, 148.43509999999998, 148.98009999999996, 149.52509999999995, 150.07009999999994, 150.61509999999993, 151.16009999999991, 151.7050999999999, 152.2500999999999, 152.79509999999988, 153.34009999999986]\n",
        "women_mean_SBP = [111.82199999999999, 112.72099999999999, 113.61999999999999, 114.51899999999999, 115.41799999999999, 116.317, 117.216, 118.115, 119.014, 119.913, 120.812, 121.5938, 122.2175, 122.8461, 123.4768, 124.808, 125.45, 126.2387, 127.1368, 128.1205, 129.2104, 130.3305, 131.2608, 132.1755, 132.5652, 133.3094, 134.2712, 135.0678, 136.1804, 137.2556, 137.6882, 139.0932, 140.3054, 141.3204, 142.0509, 142.8775, 144.2726, 145.0231, 145.8587, 146.5092, 145.9757, 146.8747, 147.7737, 148.6727, 149.5717, 150.4707, 151.3697, 152.2687, 153.1677, 154.0667, 154.9657]\n",
        "\n",
        "men_Ha = [0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9997, 0.9995, 0.9994, 0.999, 0.9993, 0.9989, 0.9991, 0.9989, 0.9983, 0.9985, 0.9984, 0.998, 0.9975, 0.997, 0.9974, 0.9966, 0.9966, 0.996, 0.9953, 0.9953, 0.9951, 0.9944, 0.9945, 0.9934, 0.9936, 0.9929, 0.9931, 0.9923, 0.9925, 0.9922, 0.9913, 0.9915, 0.9911, 0.9909, 0.99, 0.9899, 0.9898, 0.9891, 0.9881, 0.9879, 0.9873, 0.9858, 0.987, 0.9855]\n",
        "men_Hb = [1, 1, 0.9999, 1, 0.9999, 1, 0.9999, 1, 0.9999, 0.9998, 0.9997, 0.9999, 0.9997, 0.9998, 0.9997, 0.9995, 0.9996, 0.9995, 0.9994, 0.9994, 0.9991, 0.9993, 0.9989, 0.9988, 0.9987, 0.9986, 0.9984, 0.9982, 0.9979, 0.9977, 0.9971, 0.9972, 0.9965, 0.9962, 0.9953, 0.9948, 0.9944, 0.9929, 0.9924, 0.991, 0.9901, 0.9885, 0.986, 0.9848, 0.9835, 0.9817, 0.9798, 0.9763, 0.9748, 0.9717, 0.9662]\n",
        "\n",
        "women_Ha = [1, 1, 1, 1, 1, 1, 1, 0.9999, 0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9997, 0.9997, 0.9996, 0.9996, 0.9994, 0.9993, 0.9994, 0.9992, 0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9986, 0.9984, 0.9981, 0.9981, 0.9982, 0.9979, 0.998, 0.9975, 0.997, 0.9969, 0.9968, 0.9964, 0.9961, 0.9956, 0.9955, 0.9951, 0.9944, 0.9939, 0.9934, 0.993, 0.99304, 0.9913, 0.9921]\n",
        "women_Hb = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9996, 0.9995, 0.9995, 0.9994, 0.9992, 0.9992, 0.9991, 0.9989, 0.9988, 0.9986, 0.9985, 0.9982, 0.9978, 0.9976, 0.9971, 0.9967, 0.9963, 0.9957, 0.995, 0.9941, 0.993, 0.992, 0.9911, 0.9902, 0.9885, 0.9874, 0.985, 0.9832, 0.9821, 0.9797]\n",
        "\n",
        "Ha_list = [women_Ha, men_Ha]\n",
        "Hb_list = [women_Hb, men_Hb]\n",
        "\n",
        "mean_LDL_list = [women_mean_LDL, men_mean_LDL]\n",
        "mean_SBP_list = [women_mean_SBP, men_mean_SBP]\n",
        "\n",
        "Ha_list = [women_Ha, men_Ha]\n",
        "Hb_list = [women_Hb, men_Hb]\n",
        "\n",
        "mean_LDL_list = [women_mean_LDL, men_mean_LDL]\n",
        "mean_SBP_list = [women_mean_SBP, men_mean_SBP]\n",
        "\n",
        "# average BMI values for men and women\n",
        "avg_bmi = [26.98912, 27.85051]\n",
        "# average HDL values for men and women\n",
        "avg_hdl = [1.598386, 1.283341]\n",
        "\n",
        "def calculate(age, sex, ldl, ldl_rx, ldl_dec,\n",
        "              age_start_rx_ldl, age_stop_rx_ldl, hdl, sbp, sbp_rx, sbp_dec,\n",
        "              age_start_rx_sbp, age_stop_rx_sbp, smoke, fmr_tob, prevalent_diabetes_35,\n",
        "              bmi, fam_hx_chd):\n",
        "\n",
        "    past_a_sums = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "\n",
        "    dm = int(prevalent_diabetes_35)\n",
        "\n",
        "    lnRR_a_list = []\n",
        "    lnRR_b_list = []\n",
        "\n",
        "    lnRR_a = [0 for _ in range(81 - 30)]\n",
        "    lnRR_b = [0 for _ in range(81 - 30)]\n",
        "    a_t = [0 for _ in range(81 - 30)]\n",
        "    b_t = [0 for _ in range(81 - 30)]\n",
        "    c_t = [0 for _ in range(81 - 30)]\n",
        "    d_t = [0 for _ in range(81 - 30)]\n",
        "    e_t = [0 for _ in range(81 - 30)]\n",
        "    f_t = [0 for _ in range(81 - 30)]\n",
        "    m_t = [0 for _ in range(81 - 30)]\n",
        "\n",
        "    LDL_ES_mmol = [0.610294236200972 / 45, 0.696666480552631 / 40]\n",
        "    SBP_ES_mmol = [0.596822386208318 / 450, 0.562215263512178 / 400]\n",
        "\n",
        "    del_LDL = ldl - mean_LDL_list[sex][age-30]\n",
        "    del_SBP = sbp - mean_SBP_list[sex][age-30]\n",
        "\n",
        "    a_beta = [\n",
        "        [\n",
        "            0.66 * 0.85, 0.5,\n",
        "            [0.983679437374588, 0.768813402297644],\n",
        "            [0.467034851783647, 0.417294201034895],\n",
        "            0.800648203696211, 0.502003018790893,\n",
        "            0.00895775920895248, -0.632265086010107,\n",
        "            0.00305563\n",
        "        ],\n",
        "        [\n",
        "            0.66 * 0.85, 0.5,\n",
        "            [0.641703348526382, 0.4042777367951],\n",
        "            [0.396454635449883, 0.351011034242294],\n",
        "            0.690752315157672, 0.555861893739954,\n",
        "            0.0109834603573848, -0.612663093385597,\n",
        "            0.00305563\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    b_beta = [\n",
        "        [\n",
        "            0.00432149552442511, 0.0000196190161699591,\n",
        "            [1.11270781170849, 1.23876285117286],\n",
        "            [0.336045717103265, 0.462419315914295],\n",
        "            0.515257189855812, 0.0179926569543217,\n",
        "            0.0140518092696023, -0.201163272313767\n",
        "        ],\n",
        "        [\n",
        "            0.00866812947141468, 0.000260041603209642,\n",
        "            [1.29162125334208, 0.857058215628963],\n",
        "            [0.453034845319801, 0.382734719097288],\n",
        "            0.592360632788394, 0.0374768858776153,\n",
        "            0.0148344238334535, 0.00425393915728762\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    for i_a in range(30, 81):\n",
        "        a_sums = []\n",
        "        a0 = del_LDL * a_beta[sex][0] * (i_a - 20)\n",
        "        a1 = -0.12 if ldl_rx == 1 and i_a >= age_start_rx_ldl else 0\n",
        "        a2 = (i_a - age_start_rx_ldl + 1) * ldl_dec if i_a >= age_start_rx_ldl and age_stop_rx_ldl - i_a >= 0 and ldl_rx == 1 else past_a_sums[-1][2]\n",
        "        a3 = a0 + a2\n",
        "        a4 = del_SBP * a_beta[sex][1] * (i_a - 20)\n",
        "        a5 = -0.1 if sbp_rx == 1 and i_a >= age_start_rx_sbp else 0\n",
        "        a6 = (i_a - age_start_rx_sbp + 1) * sbp_dec if i_a >= age_start_rx_sbp and age_stop_rx_sbp - i_a >= 0 and sbp_rx == 1 else past_a_sums[-1][6]\n",
        "        a7 = a4 + a6\n",
        "        a8 = LDL_ES_mmol[sex] * a3 + a1\n",
        "        a9 = SBP_ES_mmol[sex] * a7 + a5\n",
        "\n",
        "        a_sums.extend([a0, a1, a2, a3, a4, a5, a6, a7, a8, a9])\n",
        "        a_sums.extend([\n",
        "            smoke * a_beta[sex][2][dm],\n",
        "            fmr_tob * a_beta[sex][3][dm],\n",
        "            prevalent_diabetes_35 * a_beta[sex][4],\n",
        "            fam_hx_chd * a_beta[sex][5],\n",
        "            (bmi - avg_bmi[sex]) * a_beta[sex][6],\n",
        "            (hdl - avg_hdl[sex]) * a_beta[sex][7],\n",
        "        ])\n",
        "\n",
        "        past_a_sums.append(a_sums)\n",
        "\n",
        "        b_sums = [\n",
        "            del_LDL * b_beta[sex][0],\n",
        "            del_SBP * b_beta[sex][1],\n",
        "            smoke * b_beta[sex][2][dm],\n",
        "            fmr_tob * b_beta[sex][3][dm],\n",
        "            prevalent_diabetes_35 * b_beta[sex][4],\n",
        "            fam_hx_chd * b_beta[sex][5],\n",
        "            (bmi - avg_bmi[sex]) * b_beta[sex][6],\n",
        "            (hdl - avg_hdl[sex]) * b_beta[sex][7]\n",
        "        ]\n",
        "\n",
        "        lnRR_a_list.append(sum(a_sums[8:]))\n",
        "        lnRR_b_list.append(sum(b_sums))\n",
        "\n",
        "    for i in range(81 - 30):\n",
        "        lnRR_a[i] = lnRR_a_list[i]\n",
        "        lnRR_b[i] = lnRR_b_list[i]\n",
        "\n",
        "        if i < age - 30:\n",
        "            a_t[i] = 0\n",
        "            b_t[i] = 0\n",
        "            c_t[i] = 0\n",
        "            d_t[i] = 0\n",
        "            e_t[i] = 0\n",
        "            f_t[i] = 0\n",
        "            m_t[i] = 0\n",
        "\n",
        "        if i == age - 30:\n",
        "            a_t[i] = 1 - (Ha_list[sex][i] ** math.exp(lnRR_a[i]))\n",
        "            b_t[i] = 1 - (Hb_list[sex][i] ** math.exp(lnRR_b[i]))\n",
        "            c_t[i] = b_t[i]\n",
        "            d_t[i] = a_t[i]\n",
        "            e_t[i] = 1 - c_t[i] - d_t[i]\n",
        "            f_t[i] = 0 + d_t[i]\n",
        "            m_t[i] = 0 + c_t[i]\n",
        "        else:\n",
        "            a_t[i] = 1 - (Ha_list[sex][i] ** math.exp(lnRR_a[i]))\n",
        "            b_t[i] = 1 - (Hb_list[sex][i] ** math.exp(lnRR_b[i]))\n",
        "            c_t[i] = e_t[i - 1] * b_t[i]\n",
        "            d_t[i] = e_t[i - 1] * a_t[i]\n",
        "            e_t[i] = e_t[i - 1] - c_t[i] - d_t[i]\n",
        "            f_t[i] = f_t[i - 1] + d_t[i]\n",
        "            m_t[i] = m_t[i - 1] + c_t[i]\n",
        "\n",
        "    return f_t"
      ],
      "metadata": {
        "id": "TO7Y8qNa1VB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rfOSDExUrZvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User profile\n",
        "\n",
        "\n",
        "```\n",
        "Global variable\n",
        "```"
      ],
      "metadata": {
        "id": "5hNbAHY55Pv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_matching_fields(target_dict, source_dict):\n",
        "    for key in source_dict:\n",
        "        if key in target_dict:\n",
        "            target_dict[key] = source_dict[key]"
      ],
      "metadata": {
        "id": "7zbGA8Pr5OLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "One field per relevant input box in the profile. Height and weight not included\n",
        "due to BMI being the relevant field for the calculation algorithm.\n",
        "get_treatment and get_recommendation receive additional fields so it's not necessary\n",
        "for user_profile to include things like \"ldl_rx\" etc.\n",
        "'''\n",
        "\n",
        "user_profile = {\n",
        "    'sex': None,\n",
        "    'age': None,\n",
        "    'LDL': None,\n",
        "    'HDL': None,\n",
        "    'SBP': None,\n",
        "    'diab': None,\n",
        "    'smoke': None,\n",
        "    'fmrtob': None,\n",
        "    'famhx': None,\n",
        "    'bmi': None\n",
        "}"
      ],
      "metadata": {
        "id": "2Vyft3qS5Uyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_risk = None"
      ],
      "metadata": {
        "id": "r0veoycG5XHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main stream"
      ],
      "metadata": {
        "id": "3danK7VOUoHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Flask app and the context history\n",
        "app = Flask(\"expert-bot\", static_folder = STATIC_DIR)\n",
        "context_history = []"
      ],
      "metadata": {
        "id": "awVdJmxOuSyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route(\"/\")\n",
        "def home():\n",
        "    html_file_path = '/content/interface/index.html'\n",
        "    with open(html_file_path, 'r') as file:\n",
        "        html_content = file.read()\n",
        "\n",
        "    return html_content"
      ],
      "metadata": {
        "id": "f_qMIchoV57j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a system prompt to guide the responses of the chatbot\n",
        "system_prompt = \"\"\"You are a helpful and informative assistant called \"Assistant\". Your goal is to provide accurate and relevant information to the user's queries.\n",
        "Please ensure that your responses are succinct, respectful, and factual. Refrain from emoting.\n",
        "If you're uncertain about a question, it's better to admit it rather than provide inaccurate information.\n",
        "Respond to the User's question ONLY. Do not impersonate the User and do not include followup questions in your response unless prompted.\"\"\""
      ],
      "metadata": {
        "id": "k5lY3UISyVNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_history += [system_prompt]"
      ],
      "metadata": {
        "id": "3Fy77rU2yb1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route(\"/interact\", methods=[\"POST\"])\n",
        "def interact():\n",
        "    global context_history\n",
        "    data = request.get_json()\n",
        "    user_input = data['query']\n",
        "\n",
        "    branch = classify(stage1_classifier, classifier_tokenizer, user_input, label_dict)\n",
        "\n",
        "    if branch == 'general information':\n",
        "        # Append user input to context as needed\n",
        "        context_history.append(f\"User: {user_input}\")\n",
        "\n",
        "        # Knowledge-based questions keep a context for the conversation.\n",
        "        conversation = '\\n'.join(context_history)\n",
        "        response_text = serve_knowledge(conversation)\n",
        "\n",
        "        # Append the formatted response to the context\n",
        "        context_history.append(f\"Assistant: {response_text['text']}\")\n",
        "\n",
        "        # Maintain a recent context window to avoid stale conversation artifacts\n",
        "        if len(context_history) > 9:\n",
        "            # keep the last 9 exchanges (4 User/Assistant pairs and the System prompt)\n",
        "            context_history = context_history[0] + context_history[-8:]\n",
        "\n",
        "        return jsonify(response_text)\n",
        "\n",
        "    elif branch == 'quantitative analysis':\n",
        "        return jsonify({\"answer\": \"quantitative_placeholder\"})\n",
        "\n",
        "    else:\n",
        "        return jsonify({\"answer\": \"Sorry, I'm not able to help you with that. Please either rephrase the question or ask a different question.\"})"
      ],
      "metadata": {
        "id": "ydF_k8joV-gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    public_url = ngrok.connect(7000)\n",
        "\n",
        "    print(f\"Flask app is running at {public_url}\")\n",
        "\n",
        "    # Run the Flask app\n",
        "    app.run(host='0.0.0.0', port=7000)"
      ],
      "metadata": {
        "id": "2v8blKF9WAsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XEgRdorAWMo7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}